{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model\n",
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [00:04, 6095555.99it/s]                                                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 61216.64it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4423680it [00:01, 2262059.86it/s]                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 22159.41it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TensorBoard setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Writing to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Inspect the model using TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Adding a “Projector” to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Tracking model training with TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Assessing trained models with TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
