{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow to implement AlexNet\n",
    "\n",
    "[reference](https://github.com/linlinyaoyao/TensorFlowPro/blob/master/%E5%9F%BA%E7%A1%80%E6%A1%88%E4%BE%8B%E6%95%99%E7%A8%8B/2.%E5%9F%BA%E4%BA%8EVisual%20Studio%20Tools%20for%20AI%E7%9A%84TensorFlow%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0CNN%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 : Import libs and define tool functions\n",
    "\n",
    "* import datetime package to get time\n",
    "* batch size = 32\n",
    "* batch count = 100\n",
    "* drop_out means randomly assign some weight to 0, and amplify other weight to 1/keep_prob, this can reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 32\n",
    "num_batches = 100\n",
    "\n",
    "# print layer name and layer shape\n",
    "def print_activation(t):\n",
    "    print(t.op.name, ' ', t.get_shape().as_list())\n",
    "    \n",
    "# return a full connect layer\n",
    "# params:\n",
    "#    input    : data input\n",
    "#    num_in   : input dimension\n",
    "#    num_out  : output dimension\n",
    "def full_connect(input, num_in, num_out, drop_out=1.0):\n",
    "    w = tf.Variable(tf.truncated_normal([num_in, num_out]))\n",
    "    b = tf.Variable(tf.truncated_normal([num_out]))\n",
    "    return tf.nn.dropout(tf.nn.relu(tf.nn.bias_add(tf.matmul(input, w), b)), keep_prob = drop_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct AlexNet\n",
    "\n",
    "* Notes\n",
    "    * [How to intuitively understand convolution(Zh)?](https://www.zhihu.com/question/22298352)\n",
    "        * Here the convolution between kernel and image is actually using kernel flipped on both height and width to multiply with the area with the same size on image. If there is matching patter, strong signal is outputted, otherwise weak signal is outputted.\n",
    "        \n",
    "    * Size calculation\n",
    "        * If not using padding. Consider 1-D case. Kernel size = a, image size = b, step = s, then final output size is (b-a+1) / s. This can be easily generalized to 2-D case.\n",
    "        \n",
    "    * What is Local Response Normalization (LRN) and why we need it? [Ref](https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/)\n",
    "        * LRN implements the lateral inhibition. This layer is useful when we are dealing with ReLU neurons. Because ReLu neurons have unbounded activations and we need LRN to normalize that. At the same time, it will dampen the responses that are uniformly large in any given local neighborhood.\n",
    "        * tf.nn.lrn ([Krizhevsky et al., ImageNet classification with deep convolutional neural networks(NIPS2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "        * LRN does not change the dimensions, the output dimension is the same as it in input.\n",
    "    * Pooling ([ref](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/))\n",
    "        * max pooling\n",
    "        * average pooling\n",
    "        * pooling is a downscaling which was aiming to solve sensitivity to feature location\n",
    "        * In image scenarios max pooling is performed better than average pooling\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    parameters = []\n",
    "    \n",
    "    # Conv layer 1\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        # Kernel dims:\n",
    "        # Dim 1,2: kernel size = 11 x 11\n",
    "        # Dim 3:   channel count = 3\n",
    "        # Dim 4:   kernel count = 64\n",
    "        # Here kernel is initialized with truncated_normal distribution, but in real case it should be real kernels for meaningful patterns\n",
    "        kernel = tf.Variable(tf.truncated_normal([11, 11, 3, 64], stddev=1e-1, dtype=tf.float32), name='weights')\n",
    "        \n",
    "        # Stride dims:\n",
    "        # Dim 1 : step length on samples, 即隔几个样本取一次。\n",
    "        # Dim 2 : step length on image width\n",
    "        # Dim 3 : step length on image height\n",
    "        # Dim 4 : step length on channel\n",
    "        # Usually setting Dim 1 and 4 to 1 to traversal all samples and channels\n",
    "        # padding = 'SAME', conv2d result is the same size as original image, it's done by filling 0 in the outbound area and do the convolution.\n",
    "        conv = tf.nn.conv2d(images, kernel, strides=[1, 4, 4, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(bias, name=scope)\n",
    "        print_activation(conv1)\n",
    "        parameters += [kernel, biases]\n",
    "    \n",
    "    lrn1 = tf.nn.lrn(conv1, 4, bias=1.0, alpha=0.001/9, beta=0.75, name='lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    print_activation(pool1)\n",
    "    \n",
    "    # Conv Layer 2\n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([5, 5, 64, 192], stddev=1e-1, dtype=tf.float32), name='weights')\n",
    "        conv = tf.nn.conv2d(pool1, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[192], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(bias, name=scope)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "    print_activation(conv2)\n",
    "    lrn2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001/9, beta=0.75, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "    print_activation(pool2)\n",
    "    \n",
    "    # Conv Layer 3\n",
    "    with tf.name_scope('conv3') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 192, 384], stddev=1e-1, dtype=tf.float32), name='weights')\n",
    "        conv = tf.nn.conv2d(pool2, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[384], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv3 = tf.nn.relu(bias, name=scope)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "    print_activation(conv3)\n",
    "    \n",
    "    # Conv Layer 4\n",
    "    with tf.name_scope('conv4') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 384, 256], stddev=1e-1, dtype=tf.float32), name='weights')\n",
    "        conv = tf.nn.conv2d(conv3, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv4 = tf.nn.relu(bias, name=scope)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "    print_activation(conv4)\n",
    "    \n",
    "    # Conv Layer 5\n",
    "    with tf.name_scope('conv5') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], stddev=1e-1, dtype=tf.float32), name='weights')\n",
    "        conv = tf.nn.conv2d(conv4, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv5 = tf.nn.relu(bias, name=scope)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "    print_activation(conv5)\n",
    "    pool5 = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool5')\n",
    "    print_activation(pool5)\n",
    "    \n",
    "    flatten = tf.reshape(pool5, [-1, 6*6*256])\n",
    "    fc_1 = full_connect(flatten, 6*6*256, 4096, 0.5)\n",
    "    fc_2 = full_connect(fc_1, 4096, 4096, 0.5)\n",
    "    fc_3 = full_connect(fc_2, 4096, 1000)\n",
    "    \n",
    "    return fc_3, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate training time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_tensorflow_run(session, target, info_string):\n",
    "    num_steps_burn_in = 10\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared = 0.0\n",
    "    \n",
    "    for i in range(num_steps_burn_in + num_batches):\n",
    "        start_time = time.time()\n",
    "        _ = session.run(target)\n",
    "        duration = time.time() - start_time\n",
    "        if i>= num_steps_burn_in:\n",
    "            if not i % 10:\n",
    "                print(r'%s: step:%d. duration = %.3f' % (datetime.now(), i - num_steps_burn_in, duration))\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration * duration\n",
    "            \n",
    "    mn = total_duration / num_batches\n",
    "    vr = total_duration_squared / num_batches - mn * mn\n",
    "    sd = math.sqrt(vr)\n",
    "    print(r'%s: %s across %d steps, %.3f +/- %.3f sec / batch' % (datetime.now(), info_string, num_batches, mn, sd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0921 18:06:46.098731  3632 deprecation.py:506] From <ipython-input-9-28928a9921f8>:21: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1   [32, 56, 56, 64]\n",
      "pool1   [32, 27, 27, 64]\n",
      "conv2   [32, 27, 27, 192]\n",
      "pool2   [32, 13, 13, 192]\n",
      "conv3   [32, 13, 13, 384]\n",
      "conv4   [32, 13, 13, 256]\n",
      "conv5   [32, 13, 13, 256]\n",
      "pool5   [32, 6, 6, 256]\n",
      "2019-09-21 18:06:53.690444: step:0. duration = 0.030\n",
      "2019-09-21 18:06:53.991448: step:10. duration = 0.030\n",
      "2019-09-21 18:06:54.291445: step:20. duration = 0.030\n",
      "2019-09-21 18:06:54.593444: step:30. duration = 0.030\n",
      "2019-09-21 18:06:54.894480: step:40. duration = 0.030\n",
      "2019-09-21 18:06:55.196444: step:50. duration = 0.030\n",
      "2019-09-21 18:06:55.498444: step:60. duration = 0.031\n",
      "2019-09-21 18:06:55.800445: step:70. duration = 0.030\n",
      "2019-09-21 18:06:56.103457: step:80. duration = 0.030\n",
      "2019-09-21 18:06:56.406446: step:90. duration = 0.030\n",
      "2019-09-21 18:06:56.677482: forward across 100 steps, 0.030 +/- 0.000 sec / batch\n",
      "2019-09-21 18:06:57.924149: step:0. duration = 0.087\n",
      "2019-09-21 18:06:58.793153: step:10. duration = 0.087\n",
      "2019-09-21 18:06:59.661746: step:20. duration = 0.086\n",
      "2019-09-21 18:07:00.528742: step:30. duration = 0.087\n",
      "2019-09-21 18:07:01.398771: step:40. duration = 0.087\n",
      "2019-09-21 18:07:02.268775: step:50. duration = 0.087\n",
      "2019-09-21 18:07:03.137741: step:60. duration = 0.086\n",
      "2019-09-21 18:07:04.011814: step:70. duration = 0.086\n",
      "2019-09-21 18:07:04.884774: step:80. duration = 0.088\n",
      "2019-09-21 18:07:05.757777: step:90. duration = 0.089\n",
      "2019-09-21 18:07:06.537810: forward-backward across 100 steps, 0.087 +/- 0.001 sec / batch\n"
     ]
    }
   ],
   "source": [
    "def run_benchmark():\n",
    "    with tf.Graph().as_default():\n",
    "        image_size = 224\n",
    "        images = tf.Variable(tf.random_normal([batch_size, image_size, image_size, 3], dtype=tf.float32, stddev=1e-1))\n",
    "        \n",
    "        fc_3, parameters = inference(images)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        \n",
    "        time_tensorflow_run(sess, fc_3, \"forward\")\n",
    "        objective = tf.nn.l2_loss(fc_3)\n",
    "        grad = tf.gradients(objective, parameters)\n",
    "        time_tensorflow_run(sess, grad, 'forward-backward')\n",
    "        \n",
    "        \n",
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
